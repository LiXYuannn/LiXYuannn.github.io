<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <div class="fixed-background"></div>
  <title>Pytorchç¬”è®°ğŸ““ç¬¬ä¸€å¼¹</title>
  <link rel="stylesheet" href="/assets/css/main.css">
  <head>
  <meta charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Luxynth's Website | Pytorchç¬”è®°ğŸ““ç¬¬ä¸€å¼¹</title>

  <link rel="preload" as="image" href="/assets/images/background.jpg">
  <link rel="preload" href="/assets/fonts/myfont.woff2" as="font" type="font/woff2" crossorigin>
  
  
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="/assets/css/post.css" />
  <link rel="stylesheet" href="/assets/css/syntax.css" />
  
  <link rel="stylesheet" href="/assets/css/common.css" />
  <script src="/assets/js/categories.js"></script>
  
  <script defer src="/assets/js/lbox.js"></script>
  
</head>

</head>
<body>

  <div id="swup">
    <main class="blogfeed">
  <section id="article">
    <div class="profile-header">
      <img src="/assets/images/avatar.jpg" class="profile-avatar">
      <h1 class="profile-title">Pytorchç¬”è®°ğŸ““ç¬¬ä¸€å¼¹</h1> 
    </div>
    <nav class="site-nav">
  <ul>
    <li><a href="/" >é¦–é¡µ</a></li>
    <li><a href="/about" >å…³äºæˆ‘</a></li>
    <li><a href="/archive" >æ–‡ç« å½’æ¡£</a></li>
    <li><a href="/explore" >æ¢ç´¢</a></li>
  </ul>
</nav>
    <div class="article-thumbnail">
      <div class="article-bottom">
        <small class="article-date">10 Aug 2025</small>
        <div class="article-categories">
          
          <a href="#!" class="article-category">æ·±åº¦å­¦ä¹ </a>
          
          <a href="#!" class="article-category">Pytorch</a>
          
        </div>
      </div>
    </div>

    <div class="article-content">
      <h3 id="pytorchçš„æ ¸å¿ƒå¼ é‡">Pytorchçš„æ ¸å¿ƒâ€”â€”å¼ é‡</h3>

<p>åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæ‰€æœ‰çš„æ•°æ®å’Œæ¨¡å‹å‚æ•°éƒ½ç”¨å¼ é‡è¡¨ç¤ºã€‚</p>

<p>å¼ é‡ï¼ˆTensorï¼‰å¯ä»¥çœ‹æˆæ˜¯ï¼š</p>

<ul>
  <li><strong>0 ç»´</strong>ï¼šæ ‡é‡ï¼ˆscalarï¼‰ï¼Œæ¯”å¦‚ 3</li>
  <li><strong>1 ç»´</strong>ï¼šå‘é‡ï¼ˆvectorï¼‰ï¼Œæ¯”å¦‚ [1, 2, 3]</li>
  <li><strong>2 ç»´</strong>ï¼šçŸ©é˜µï¼ˆmatrixï¼‰</li>
  <li><strong>3 ç»´åŠä»¥ä¸Š</strong>ï¼šé«˜ç»´æ•°ç»„ï¼Œæ¯”å¦‚ä¸€æ‰¹å›¾ç‰‡ (batch_size, height, width, channels)</li>
</ul>

<p>ğŸ“Œ åœ¨ PyTorch é‡Œï¼š</p>

<ul>
  <li><strong>torch.tensor()</strong> åˆ›å»ºå¼ é‡</li>
  <li><strong>.shape</strong> æŸ¥çœ‹ç»´åº¦</li>
  <li><strong>.dtype</strong> æ•°æ®ç±»å‹</li>
  <li><strong>.to(device)</strong> æŠŠå¼ é‡æ”¾åˆ° CPU/GPU</li>
</ul>

<h3 id="gpuåŠ é€Ÿ">GPUåŠ é€Ÿ</h3>

<p>å¦‚æœæœ‰GPUï¼ŒPyTorch ä¼šè‡ªåŠ¨å¸®ä½ ç”¨ CUDA åŠ é€Ÿ</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="è‡ªåŠ¨æ±‚å¯¼">è‡ªåŠ¨æ±‚å¯¼</h3>

<p>PyTorch å¯ä»¥è‡ªåŠ¨è®¡ç®—æ¢¯åº¦ï¼Œè¿™å°±æ˜¯æ·±åº¦å­¦ä¹ è®­ç»ƒçš„åŸºç¡€ã€‚</p>

<ul>
  <li>åˆ›å»ºå¼ é‡æ—¶åŠ  requires_grad=Trueï¼ŒPyTorch ä¼šè®°å½•è®¡ç®—å›¾ã€‚</li>
  <li>è°ƒç”¨ .backward() è‡ªåŠ¨åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦ã€‚</li>
  <li>æ¢¯åº¦å­˜æ”¾åœ¨ .grad é‡Œã€‚</li>
</ul>

<h4 id="ç¬¬ä¸€ä¸ªpytorchæ–‡ä»¶">ç¬¬ä¸€ä¸ªPytorchæ–‡ä»¶</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#myfirstPytorch
</span><span class="kn">import</span> <span class="nn">torch</span>
<span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">__version__</span><span class="p">)</span>
  
<span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s">"x:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">x</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"y:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="n">z</span><span class="o">=</span><span class="n">x</span><span class="o">+</span><span class="n">y</span>
<span class="k">print</span><span class="p">(</span><span class="s">"z:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">z</span><span class="p">)</span>

<span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span>
<span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"è®¾å¤‡:"</span><span class="p">,</span><span class="n">device</span><span class="p">)</span>
  
<span class="n">a</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">b</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="n">c</span><span class="o">=</span><span class="n">a</span><span class="o">*</span><span class="n">b</span>
<span class="n">out</span><span class="o">=</span><span class="n">c</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
<span class="n">out</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"açš„æ¢¯åº¦:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">a</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#è¿è¡Œç»“æœ</span>
2.6.0
x:
 tensor<span class="o">([[</span>1., 2.],
        <span class="o">[</span>3., 4.]]<span class="o">)</span>
y:
 tensor<span class="o">([[</span>1., 1.],
        <span class="o">[</span>1., 1.]]<span class="o">)</span>
x:
 tensor<span class="o">([[</span>2., 3.],
        <span class="o">[</span>4., 5.]]<span class="o">)</span>
è®¾å¤‡: cpu
açš„æ¢¯åº¦:
 tensor<span class="o">([[</span> 0.4779,  1.5350,  0.0037,  1.2580],
        <span class="o">[</span><span class="nt">-0</span>.5812,  1.6379,  0.7242,  1.2655],
        <span class="o">[</span><span class="nt">-0</span>.6917, <span class="nt">-0</span>.8033, <span class="nt">-1</span>.8678, <span class="nt">-1</span>.1883]]<span class="o">)</span>

</code></pre></div></div>

<h3 id="è¿›é˜¶ä»»åŠ¡-ï¸">è¿›é˜¶ä»»åŠ¡ ğŸ–Šï¸</h3>
<ul>
  <li>åˆ›å»ºä¸€ä¸ª (2, 3, 4) çš„éšæœºå¼ é‡ tï¼ˆfloat ç±»å‹ï¼‰</li>
  <li>å¯¹å®ƒåšï¼š
    <ul>
      <li>åŠ æ³•ï¼ˆ+ 1ï¼‰</li>
      <li>å‡æ³•ï¼ˆ- 0.5ï¼‰</li>
      <li>çŸ©é˜µä¹˜æ³•ï¼ˆç”¨ .matmul() æˆ– @ï¼‰*</li>
    </ul>
  </li>
  <li>æŠŠå®ƒç§»åˆ° GPUï¼ˆå¦‚æœæ²¡æœ‰ GPU å°±ä¾ç„¶ç”¨ CPUï¼‰ï¼Œå¹¶æ‰“å°ï¼š
    <ul>
      <li>.shape</li>
      <li>.dtype</li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">t</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s">"t:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">t</span><span class="p">)</span>
<span class="n">a</span><span class="o">=</span><span class="n">t</span><span class="o">+</span><span class="n">x</span>
<span class="n">b</span><span class="o">=</span><span class="n">t</span><span class="o">-</span><span class="n">x</span><span class="o">*</span><span class="mf">0.5</span>
  
<span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span>
<span class="c1"># t=t.to(device)
# x=x.to(device)
# a=a.to(device)
# b=b.to(device)
</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="n">tensor</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">]]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"è®¾å¤‡:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">device</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"a:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">a</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"b:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
  
<span class="k">print</span><span class="p">(</span><span class="s">".shape:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">".dtype:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">t</span><span class="p">.</span><span class="n">dtype</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#è¿è¡Œç»“æœ</span>
t:
 tensor<span class="o">([[[</span><span class="nt">-0</span>.5283,  1.2119,  1.6814,  0.6434],
         <span class="o">[</span><span class="nt">-0</span>.3742, <span class="nt">-0</span>.8421, <span class="nt">-1</span>.6161,  0.2300],
         <span class="o">[</span><span class="nt">-1</span>.2224,  0.4019, <span class="nt">-1</span>.4070,  0.4027]],

        <span class="o">[[</span> 0.0407, <span class="nt">-0</span>.5536, <span class="nt">-0</span>.7496,  1.7721],
         <span class="o">[</span> 1.4842,  0.2181, <span class="nt">-0</span>.0732, <span class="nt">-1</span>.1741],
         <span class="o">[</span> 0.4077, <span class="nt">-0</span>.7331, <span class="nt">-2</span>.2628,  0.8560]]]<span class="o">)</span>
è®¾å¤‡:
 cpu
a:
 tensor<span class="o">([[[</span> 0.4717,  2.2119,  2.6814,  1.6434],
         <span class="o">[</span> 0.6258,  0.1579, <span class="nt">-0</span>.6161,  1.2300],
         <span class="o">[</span><span class="nt">-0</span>.2224,  1.4019, <span class="nt">-0</span>.4070,  1.4027]],

        <span class="o">[[</span> 1.0407,  0.4464,  0.2504,  2.7721],
         <span class="o">[</span> 2.4842,  1.2181,  0.9268, <span class="nt">-0</span>.1741],
         <span class="o">[</span> 1.4077,  0.2669, <span class="nt">-1</span>.2628,  1.8560]]]<span class="o">)</span>
b:
 tensor<span class="o">([[[</span><span class="nt">-1</span>.0283,  0.7119,  1.1814,  0.1434],
         <span class="o">[</span><span class="nt">-0</span>.8742, <span class="nt">-1</span>.3421, <span class="nt">-2</span>.1161, <span class="nt">-0</span>.2700],
         <span class="o">[</span><span class="nt">-1</span>.7224, <span class="nt">-0</span>.0981, <span class="nt">-1</span>.9070, <span class="nt">-0</span>.0973]],

        <span class="o">[[</span><span class="nt">-0</span>.4593, <span class="nt">-1</span>.0536, <span class="nt">-1</span>.2496,  1.2721],
         <span class="o">[</span> 0.9842, <span class="nt">-0</span>.2819, <span class="nt">-0</span>.5732, <span class="nt">-1</span>.6741],
         <span class="o">[</span><span class="nt">-0</span>.0923, <span class="nt">-1</span>.2331, <span class="nt">-2</span>.7628,  0.3560]]]<span class="o">)</span>
.shape:
 torch.Size<span class="o">([</span>2, 3, 4]<span class="o">)</span>
.dtype:
 torch.float32
 
</code></pre></div></div>

<blockquote>
  <p>çŸ©é˜µä¹˜æ³•çš„å®ç°
â€”â€”ç”¨ .matmul() æˆ– @</p>
</blockquote>

<p>å› ä¸ºå¼ é‡tç›¸å½“äº2ä¸ª3* 4çš„çŸ©é˜µï¼Œä¸èƒ½ç›´æ¥å’Œè‡ªå·±ç›¸ä¹˜ï¼Œæ‰€ä»¥éœ€è¦å†éšæœºç”Ÿæˆä¸€ä¸ªï¼ˆ2ï¼Œ4ï¼Œkï¼‰çš„çŸ©é˜µ//ä»¤k=6</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">t</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">s</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
  
<span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span>
<span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="p">[</span><span class="n">tensor</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="p">[</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="p">]]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"è®¾å¤‡:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">device</span><span class="p">)</span>
  
<span class="n">out</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="p">)</span>
<span class="c1">#æˆ–è€…out=t@s
</span><span class="k">print</span><span class="p">(</span><span class="s">"out:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">out</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">".shape:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">out</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">".dtype:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">out</span><span class="p">.</span><span class="n">dtype</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#è¿è¡Œç»“æœ</span>
è®¾å¤‡:
 cpu
out:
 tensor<span class="o">([[[</span><span class="nt">-0</span>.6649, <span class="nt">-0</span>.7129,  1.1296, <span class="nt">-1</span>.8482,  1.4739,  0.7178],
         <span class="o">[</span><span class="nt">-1</span>.5440,  4.1733, <span class="nt">-3</span>.7995, <span class="nt">-1</span>.6282, <span class="nt">-3</span>.5405, <span class="nt">-0</span>.3269],
         <span class="o">[</span> 2.4297, <span class="nt">-4</span>.6300,  0.9426,  2.7147,  1.8590,  4.4622]],

        <span class="o">[[</span> 1.0501,  0.4767,  1.8069, <span class="nt">-3</span>.8165,  2.4047, <span class="nt">-1</span>.2312],
         <span class="o">[</span><span class="nt">-1</span>.2006,  0.1548, <span class="nt">-0</span>.6207,  1.4950, <span class="nt">-1</span>.4686,  1.2318],
         <span class="o">[</span><span class="nt">-1</span>.5264,  0.0297, <span class="nt">-0</span>.2412, <span class="nt">-1</span>.4789,  1.6743, <span class="nt">-1</span>.2765]]]<span class="o">)</span>
.shape:
 torch.Size<span class="o">([</span>2, 3, 6]<span class="o">)</span>
.dtype:
 torch.float32
 
</code></pre></div></div>



      

        
       
      

      

        
       
      

      <div class="related-posts">
        <h2>ç›¸å…³æ–‡ç« </h2>
        <ul>
          
          
            
              
              

              
            
          
            
              
              

              
                
                  <li>
                    <a href="/posts/Awesome_AIGC_Detection/">Awesome-AIGC-Detection</a>
                    <small>2025å¹´08æœˆ15æ—¥</small>
                  </li>
                  
                
              
            
          
            
              
              

              
            
          
            
          
            
              
              

              
                
                  <li>
                    <a href="/posts/LLM%E7%AE%80%E4%BB%8B/">LLMç®€ä»‹</a>
                    <small>2025å¹´07æœˆ20æ—¥</small>
                  </li>
                  
                
              
            
          
            
              
              

              
                
                  <li>
                    <a href="/posts/MLLM%E7%9A%84AIGC%E6%A3%80%E6%B5%8B/">MLLMçš„AIGCæ£€æµ‹</a>
                    <small>2025å¹´05æœˆ03æ—¥</small>
                  </li>
                  
                
              
            
          
            
              
              

              
                
              
            
          
            
              
              

              
            
          
        </ul>
      </div>

      

      <h6>è¯´ç‚¹ä»€ä¹ˆâ€¦</h6>

<div id="vcomments"></div>
    <script src='//unpkg.com/valine/dist/Valine.min.js'></script>
    <script>
        new Valine({
            el: '#vcomments',
            appId: 'it55DzxX1q0dJJ3x27Ietfhq-gzGzoHsz',
            appKey: '0voRk494pOPc2N4hBNvAtgIa',
            placeholder: 'æ¬¢è¿æ‰“æ‰°ï¼',
            avatar: 'mp'
        })
    </script>
    </div>
  </section>
</main>


  </div>

  <footer>
   <div class="friends-links-container">
      <div class="friends-links-header">
        <p>Friend_LinkğŸ˜</p>
      </div>
        
      <div class="friends-list">
            
        <div class="friend-item">
          <a href="https://www.cclmsy.cc" target="_blank" rel="noopener noreferrer">
            <img src="/assets/images/cclmsy.jpg" alt="å¥½å‹ä¸€" class="friend-avatar">
          </a>
          <span class="friend-name">æ·±ç¿¼cclmsy</span>
        </div>
            
        <!-- <div class="friend-item">
          <a href="https://another-example.com" target="_blank" rel="noopener noreferrer">
            <img src="/path/to/friend-avatar2.jpg" alt="å¥½å‹äºŒ" class="friend-avatar">
          </a>
          <span class="friend-name">å¥½å‹äºŒ</span>
        </div> -->
            
      </div>
    </div>
    <p class="ps">â€”â€” å¦‚æœä½ ä¹Ÿæƒ³æ·»åŠ å‹é“¾ï¼Œç›¸è§å…³äºæˆ‘çš„é¡µé¢æˆ–è€…é‚®ç®±è”ç³»æˆ‘ï¼ğŸ‰</p>
    <hr>
      <p>&copy; 2025 | Luxynth</p>

</footer>

  <section id="category-modal-bg"></section>
<section id="category-modal">
  <h1 id="category-modal-title"></h1>
  <section id="category-modal-content"></section>
</section>

  
<!-- æ‡’åŠ è½½ -->
  <script>
      window.addEventListener('DOMContentLoaded', (event) => {
        const images = document.querySelectorAll('img');
        images.forEach(image => {
          if (!image.hasAttribute('loading')) {
            image.setAttribute('loading', 'lazy');
          }
        });
      });
    </script>

  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  <script src="/assets/js/script.js"></script>
  <div class="announcement-container">
   <div class="announcement-icon" id="announcement-icon">
        <img src="/assets/images/logo.svg" alt="å…¬å‘Šå›¾æ ‡">
    </div>
    <div class="announcement-panel" id="announcement-panel">
        <span class="close-btn">&times;</span>
            <div class="announcement-content">
                <div class="announcement-header">
                <p>å…¬å‘Šæ ğŸª§</p>
            </div>
            <p>ğŸ“Œäº²çˆ±çš„è¯»è€…ï¼Œè¿™é‡Œæ˜¯Luxynthçš„å°ç ´ç«™ğŸŒ»ï½</p>
            <p>ğŸ“Œå¾ˆé«˜å…´ï¼Œæˆ‘ä»¬åœ¨è¿™ç‰‡å¹¿è¢¤çš„ç½‘ç»œä¸–ç•Œç›¸é‡ã€‚è¯·éšæ„æ¼«æ­¥ï¼Œè¿™é‡Œçš„ä¸€åˆ‡éƒ½çŒ®ç»™ä½ â¤ï¸</p>
            <p>ğŸ“Œæ–‡ç« æŒç»­æ›´æ–°ä¸­ï¼Œæ¬¢è¿ä½ ç»å¸¸æ¥è®¿ï½</p>

        </div>
    </div>
</div>

</body>
</html>